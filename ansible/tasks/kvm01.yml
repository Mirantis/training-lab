# https://docs.mirantis.com/mcp/master/mcp-deployment-guide/deploy-mcp-drivetrain/automated-deployment-of-mcp-drivetrain.html

- name: Install packages for kvm01
  apt:
    name: "{{ item }}"
  loop: "{{ kvm01_packages }}"

- name: Create /home/{{ default_student_account_name }}/.vnc directory
  file:
    path: /home/{{ default_student_account_name }}/.vnc
    state: directory
    mode: 0700

- block:
  - name: Set VNC password in /home/{{ default_student_account_name }}/.vnc/passwd
    shell: umask 077; echo "{{ default_access_password }}" | vncpasswd -f > /home/{{ default_student_account_name }}/.vnc/passwd
    args:
      creates: /home/{{ default_student_account_name }}/.vnc/passwd
    changed_when: false

  # TODO - this should be doine using ACME and Let's Encrypt
  - name: Create certificate for novnc
    command: openssl req -x509 -nodes -newkey rsa:2048 -keyout /etc/ssl/novnc.pem -out /etc/ssl/novnc.pem -days 365 -subj "/C=CZ/ST=Czech/L=Prague/O=Mirantis/CN={{ ansible_domain }}"
    args:
      creates: /etc/ssl/novnc.pem
    when: ansible_domain != ''
  when: packer_build_name is not defined

- name: Add xstartup to student account /home/{{ default_student_account_name }}/.vnc/xstartup
  template:
    src: templates/vnc-xstartup.j2
    dest: /home/{{ default_student_account_name }}/.vnc/xstartup
    mode: 0755

- name: Change owner of /home/{{ default_student_account_name }}/.vnc to {{ default_student_account_name }}:{{ default_student_account_name }}
  file:
    path: /home/{{ default_student_account_name }}/.vnc
    owner: "{{ default_student_account_name }}"
    group: "{{ default_student_account_name }}"
    recurse: yes

- name: Improve VNC output (no jpg compression)
  replace:
    path: /usr/share/novnc/include/rfb.js
    regexp: "{{ item.regexp }}"
    replace: "{{ item.replace }}"
  loop:
    - regexp: "//(\\['compress_lo',      -255 \\],)"
      replace: '\1'
    - regexp: "^(\\s+)(\\['compress_hi',        -247 \\],)"
      replace: '\1//\2'

- name: Enable vncserver + https acces on ufw
  ufw:
    rule: allow
    port: "{{ item }}"
    proto: tcp
  loop:
    - 443
    - 5901

- name: Add vncserver to the systemd
  template:
    src: templates/vncserver-service.j2
    dest: /etc/systemd/system/vncserver@.service
  notify: reload systemd

- name: Add systemd service for novnc
  template:
    src: templates/novnc.service.j2
    dest: /etc/systemd/system/novnc.service
  notify:
    - reload systemd
    - restart novnc

- name: Add port forwarding for Jenkins and MAAS to be accessible form Public IP
  blockinfile:
    path: /etc/ufw/before.rules
    insertbefore: Don't delete these required lines, otherwise there will be errors
    block: |
      # nat Table rules
      *nat
      :POSTROUTING ACCEPT [0:0]
      :PREROUTING ACCEPT [0:0]

      {% for network in networks.items() | sort(attribute='1.subnet_netmask') %}
      # Masquarade traffic for {{ network.0 }} [{{ network.1.subnet_netmask }}] going out of {{ ansible_default_ipv4.interface }}
      -A POSTROUTING -s {{ network.1.subnet_netmask }} -o {{ ansible_default_ipv4.interface }} -j MASQUERADE
      {% endfor %}

      # Add port forwarding
      # Jenkins: http://{{ inventory_hostname }}:8081 -> http://{{ mcp_salt_master_ip }}:8081
      -A PREROUTING -i {{ ansible_default_ipv4.interface }} -d {{ ansible_default_ipv4.address }} -p tcp --dport 8081 -j DNAT --to-destination {{ mcp_salt_master_ip }}:8081
      # MAAS: http://{{ inventory_hostname }}/MAAS -> http://{{ mcp_salt_master_ip }}/MAAS
      -A PREROUTING -i {{ ansible_default_ipv4.interface }} -d {{ ansible_default_ipv4.address }} -p tcp --dport 5240 -j DNAT --to-destination {{ mcp_salt_master_ip }}:5240

      COMMIT
  when: packer_build_name is not defined
  notify:
    - restart ufw

- name: Execute all notify sections
  meta: flush_handlers

- block:
  - name: Start vncserver when booting
    service:
      name: vncserver@1.service
      enabled: yes
      state: started

  - name: Start novnc when booting
    service:
      name: novnc
      enabled: yes
      state: started
  when: packer_build_name is not defined

- name: Download VM image
  get_url:
    url: "{{ mcp_cfg01_image_url }}"
    dest: /root/cfg01-day01.qcow2
    tmp_dest: /var/tmp/

- name: Clone repository with salt-model ({{ mcp_salt_model_git_repository }})
  git:
    repo: "{{ mcp_salt_model_git_repository }}"
    dest: /root/model

- name: Clone repository with mk-pipelines
  git:
    repo: "{{ mcp_mk_pipelines_git_repository }}"
    dest: /root/mk-pipelines
    version: "{{ mcp_release_tag }}"

- name: Clone repository with pipeline-library
  git:
    repo: "{{ mcp_pipeline_library_git_repository }}"
    dest: /root/pipeline-library
    version: "{{ mcp_release_tag }}"

- name: Download create-config-drive script ({{ mcp_create_config_drive_script_url }})
  get_url:
    url: "{{ mcp_create_config_drive_script_url }}"
    dest: /root/create-config-drive
    mode: 0755

- name: Download master_config script ({{ mcp_master_config_script_url }})
  get_url:
    url: "{{ mcp_master_config_script_url }}"
    dest: /root/user_data.sh
    mode: 0755

# Fix bug (https://gerrit.mcp.mirantis.net/#/c/22492) !!!!! xxxx TODO
- name: Enable setting MTU on cfg01
  blockinfile:
    path: /root/user_data.sh
    backup: yes
    marker: "# {mark} ANSIBLE MANAGED BLOCK - Enable setting MTU"
    insertafter: "pidof /sbin/dhclient"
    block: |
      sed -i.orig '/gateway/i \ \ mtu $DEPLOY_NETWORK_MTU' /root/interfaces

# This is by default done by Jenkins which is building the .iso
- name: Change the params in /root/user_data.sh "{{ mcp_master_config_script_url }}"
  lineinfile:
    path: /root/user_data.sh
    regexp: "{{ item.regexp }}"
    line: "{{ item.line }}"
  loop:
    - { regexp: '^export SALT_MASTER_DEPLOY_IP', line: 'export SALT_MASTER_DEPLOY_IP={{ mcp_salt_master_ip }}' }
    - { regexp: '^export SALT_MASTER_MINION_ID', line: 'export SALT_MASTER_MINION_ID=cfg01.{{ domain }}' }
    - { regexp: '^export DEPLOY_NETWORK_GW', line: 'export DEPLOY_NETWORK_GW={{ networks.deploy_network.gateway }}' }
    - { regexp: '^export DEPLOY_NETWORK_NETMASK', line: 'export DEPLOY_NETWORK_NETMASK={{ networks.deploy_network.netmask }}' }
    - { regexp: '^export DEPLOY_NETWORK_MTU', line: 'export DEPLOY_NETWORK_MTU=1450' }
    #- { regexp: '^export DNS_SERVERS=8.8.8.8', line: 'export DNS_SERVERS=...' }
    - { regexp: '^export MCP_VERSION', line: 'export MCP_VERSION="{{ saltstack_repository_version }}"' }
    # Fix bug (https://gerrit.mcp.mirantis.net/#/c/22842/) !!!!! xxxx TODO
    - { regexp: '^for i in', line: 'for i in $(salt-key -l accepted | grep -v Accepted | grep -v {{ domain }} | grep -v "$SALT_MASTER_MINION_ID"); do' }

- name: Download define-vm script ({{ mcp_define_vm_script_url }})
  get_url:
    url: "{{ mcp_define_vm_script_url }}"
    dest: /root/define-vm.sh
    mode: 0755

- block:
  - name: Create directory /var/lib/libvirt/images/cfg01/
    file:
      path: /var/lib/libvirt/images/cfg01
      state: directory

  - name: Copy the original cfg01-day01 to {{ mcp_cfg01_vm_source_disk }}
    copy:
      src: /root/cfg01-day01.qcow2
      dest: "{{ mcp_cfg01_vm_source_disk }}"
      force: no
      remote_src: yes

  - name: Create the iso from salt model
    command: /root/create-config-drive -u /root/user_data.sh --ssh-key ~/.ssh/id_ed25519.pub -h cfg01 --model /root/model --mk-pipelines /root/mk-pipelines --pipeline-library /root/pipeline-library {{ mcp_cfg01_vm_config_disk }}
    args:
      creates: "{{ mcp_cfg01_vm_config_disk }}"

  - name: Define the cfg01 VM
    command: /root/define-vm.sh
    args:
      chdir: /root
      creates: "/root/cfg01.{{ domain }}-vm.xml"
    environment:
      VM_NAME: "cfg01.{{ domain }}"
      VM_SOURCE_DISK: "{{ mcp_cfg01_vm_source_disk }}"
      VM_CONFIG_DISK: "{{ mcp_cfg01_vm_config_disk }}"
      VM_MGM_BRIDGE_NAME: "{{ networks.deploy_network.device }}"
      VM_CTL_BRIDGE_NAME: "{{ networks.control_network.device }}"
      VM_MEM_KB: "{{ mcp_cfg01_vm_mem_kb }}"
      VM_CPUS: "{{ mcp_cfg01_vm_cpus }}"
    register: define_vm_output
    changed_when: define_vm_output.stdout is search('defined from')

  - name: Start cfg01.{{ domain }}
    virt:
      name: cfg01.{{ domain }}
      state: running

  - name: Notes...
    debug:
      msg:
        - "Check the installation output: ssh {{ default_student_account_name }}@{% if cloud_platform == 'azure' %}{{ ansible_fqdn }}{% else %}{{ ansible_host }}{% endif %}; virsh console cfg01.{{ domain }}"
        - "Add your ssh public key into the default MAAS account: http://{% if cloud_platform == 'azure' %}{{ ansible_fqdn }}{% else %}{{ ansible_host }}{% endif %}:5240/MAAS (mirantis/r00tme)"
        - "Add VMs for comissioning+deploy (run on cfg01): for A in {1..{{ vm_nodes_kvm }}}; do for B in {1..{{ nested_vms_count }}}; do maas mirantis machines create power_parameters_power_address=qemu+tcp://10.0.0.1$A/system hostname={{ prefix }}-kvm0$A-pxe0$B power_type=virsh power_parameters_power_id={{ prefix }}-kvm0$A-pxe0$B architecture=amd64/generic mac_addresses=52:54:00:00:0$A:0$B; done; done"
        - "MAAS   : http://{% if cloud_platform == 'azure' %}{{ ansible_fqdn }}{% else %}{{ ansible_host }}{% endif %}:5240/MAAS (mirantis/r00tme)"
        - "Jenkins: http://{% if cloud_platform == 'azure' %}{{ ansible_fqdn }}{% else %}{{ ansible_host }}{% endif %}:8081 (admin/r00tme)"
        - "noVNC  : https://{% if cloud_platform == 'azure' %}{{ ansible_fqdn }}{% else %}{{ ansible_host }}{% endif %}/vnc.html?port=443&true_color=1&password={{ default_access_password }}"
        - "VNC    : vnc://{% if cloud_platform == 'azure' %}{{ ansible_fqdn }}{% else %}{{ ansible_host }}{% endif %}:5901, Password: {{ default_access_password }}"
        - "SSH    : ssh -a -o PreferredAuthentications=password -o PubkeyAuthentication=no -o ControlPath=none {{ default_student_account_name }}@{% if cloud_platform == 'azure' %}{{ ansible_fqdn }}{% else %}{{ ansible_host }}  | {{ ansible_hostname }}{% endif %}, Password: {{ default_access_password }}"
        - "Password file location: {{ access_password_prefix_file }}"
        - "New ssh key location  : {{ access_ssh_key_prefix_file }}"
        - "Nodes  : {% for node in groups['all'] if node | regex_search(ansible_domain) %}{{ hostvars[node].public_ip }} / {{ hostvars[node].ansible_fqdn }}{% if not loop.last %}, {% endif %}{% endfor %}"
  when: packer_build_name is not defined

